# MobileNet Benchmark on TCC750X

Below is benchmark data for various **MobileNet models** running on the **TCC750X (N-Dolphin)** platform.  
MobileNet is a family of lightweight and efficient convolutional neural networks optimized for **image classification** tasks, especially on **embedded and mobile devices**.  
<!-- This benchmark showcases how different MobileNet variants (e.g., V1, V2, V3) perform when compiled, quantized (INT8), and executed on the TCC750X board. -->

All models are evaluated using the **ImageNet validation dataset** and compiled with the **tc-nn-toolkit**.  
You can click each model name in the table to download the binary ready for deployment on the device.

---

### ðŸ“Š How to Read the Table Below

| Column                    | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| **Model**                | Name of the neural network model (clickable for download, if available)     |
| **Framework**            | Deep learning framework used (e.g., PyTorch, TFLite, ONNX)                  |
| **Dataset**              | Evaluation dataset used (e.g., ImageNet validation set with 50,000 images)  |
| **Input Size (WxHxC)**   | Model input resolution and channel configuration                            |
| **Quantization Bit**     | Bit-depth used for quantization (e.g., INT8)                                |
| **Binary Files Info.**   | Size of the compiled neural network binaries for TCC750X                    |
| **Inference Time (ms)**  | Measured on the N-Dolphin EVB using zero-padded input images                |
| **Accuracy**             | Classification top-1 accuracy on ImageNet validation dataset (50,000 images)                    |
| **References**           | Link to the original GitHub repository of the model      

- - -
<!--
ì•„ëž˜ëŠ” TCC750Xì—ì„œ ì‹¤í–‰ë˜ëŠ” Classification ëª¨ë¸ì˜ ë²¤ì¹˜ë§ˆí¬ ìžë£Œìž…ë‹ˆë‹¤.
ì´ í‘œë¥¼ í†µí•´ ê° ì‹ ê²½ë§ì´ N-Dolphin (TCC750X) ë³´ë“œì—ì„œ ì‹¤í–‰ë  ë•Œì˜ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
ë˜í•œ, ì‹ ê²½ë§ ì´ë¦„ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ë³´ë“œì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìžˆëŠ” í˜•ì‹ì˜ ê²°ê³¼ë¬¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

ì°¸ì¡°ì‚¬í•­
Evaluation: tc-nn-toolkitì„ ì´ìš©í•˜ì—¬ ì¸¡ì •í•œ ê²°ê³¼ìž…ë‹ˆë‹¤.
- Evaluation Resultì˜ FP32: .enlight í™•ìž¥ìžë¡œ ë³€í™˜ëœ ìƒíƒœì—ì„œ ì¸¡ì •ëœ ê°’ìž…ë‹ˆë‹¤.
Inference Time: N-Dolphin EVBì—ì„œ ì‹¤í–‰í•œ ê²°ê³¼ìž…ë‹ˆë‹¤.
Reference: ì‹ ê²½ë§ ëª¨ë¸ì˜ ì›ë³¸ GitHub ë§í¬ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.
-->

<table border="1" cellspacing="0" cellpadding="5">
    <thead>
        <tr>
            <th rowspan="2">Model</th>
            <th rowspan="2">Framework</th>
            <th rowspan="2">DataSet</th>
            <th rowspan="2">Input Size (WxHxC)</th>
            <th rowspan="2">Quantization Bit</th>
            <th colspan="2">Binary Files Info.</th>
            <th rowspan="2">Inference Time(ms)</th>
            <th colspan="2">Accuracy</th>
            <th rowspan="2">References</th>
        </tr>
        <tr>
            <th>Weight & Bias Bin.(MB)</th>
            <th>Command Bin.(KB)</th>
            <th>FP32</th>
            <th>INT8</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td align="center"><a href="mobileNetv2_10/">MobileNetv2-10</a></td> <!-- Model -->
            <td align="center">MXNet</td> <!-- Framework -->
            <td align="center">ImageNet</td> <!-- Detections/DataSet -->
            <td align="center">224x224x3</td> <!-- Input Size (WxHxC) -->
            <td align="center">INT8</td> <!-- Quantization Bit -->
            <td align="center">4</td> <!-- Compiled NN Information: Weight, Bias Binary Size(MB) -->
            <td align="center">44</td> <!-- Compiled NN Information: Command Binary Size(KB) -->
            <td align="center">1.31</td> <!-- Inference Time(msec): EVB -->
            <td align="center">0.6984</td> <!-- Evaluation Result: FP32 -->
            <td align="center">0.6879</td> <!-- Evaluation Result: INT8 -->
            <td align="center"><a href="https://github.com/onnx/models/tree/main/validated/vision/classification/mobilenet">GitHub<a></td> <!-- References: Link -->
        </tr>
    </tbody>
</table>

- - -

## ðŸ“¤ Output Format

- The output is a 1D tensor of **1000 class scores** (ImageNet classes).
- Apply **softmax** to obtain class probabilities.
- Return the top-k predicted class indices and confidence scores.

- - -

## ðŸ”— Official Resources
- ðŸ’» [MobileNet ONNX Github](https://github.com/onnx/models/tree/main/validated/vision/classification/mobilenet)
- ðŸ“œ [MobileNet Paper](https://arxiv.org/abs/1801.04381)